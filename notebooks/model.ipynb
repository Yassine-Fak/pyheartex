{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POC1 vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "output_dir = \"../models\"\n",
    "image_dir = \"../car_dataset/small_trainning_set\"\n",
    "result_file = \"../my_project/export/result.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "tests"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest \n",
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class TaskData(BaseModel):\n",
    "    image_url: str\n",
    "\n",
    "class ResultValue(BaseModel):\n",
    "    \"\"\"\n",
    "    A class representing the value of a task completion result in Label Studio\n",
    "    i.e. the label or the labels of a given input\n",
    "    \"\"\"\n",
    "    choices: List[str]\n",
    "\n",
    "class CompletionResult(BaseModel):\n",
    "    \"\"\"\n",
    "    A class representing a task completion result in Label Studio\n",
    "    \"\"\"\n",
    "    from_name: str\n",
    "    id: str\n",
    "    to_name: str\n",
    "    type: str\n",
    "    value: ResultValue\n",
    "\n",
    "class TaskCompletion(BaseModel):\n",
    "    \"\"\"\n",
    "    A class representing a task completion in Label Studio\n",
    "    \"\"\"\n",
    "    id: int\n",
    "    lead_time: float\n",
    "    result: List[CompletionResult]\n",
    "\n",
    "class Task(BaseModel):\n",
    "    \"\"\"\n",
    "    A class representing a Label Studio task\n",
    "    \"\"\"\n",
    "    id: int\n",
    "    completions: List[TaskCompletion]\n",
    "    data: TaskData\n",
    "    task_path: str\n",
    "\n",
    "class ExportedResults(BaseModel):\n",
    "    \"\"\"\n",
    "    A class representing exported results from Label Sudio\n",
    "    \"\"\"\n",
    "    tasks: List[Task]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "class LabelStudioDataFetcher:\n",
    "    \"\"\"\n",
    "    This class allows parsing the the result returned by LabelStudio\n",
    "    and feed it into fastai classifier in order to train a model.\n",
    "    \n",
    "    Examples:\n",
    "    --------\n",
    "    >>> result_file = \"../my_project/export/result.json\"\n",
    "    >>> fetcher = LabelStudioDataFetcher(result_file)\n",
    "    >>> fetcher.path\n",
    "    PosixPath('../my_project/export/result.json')\n",
    "    >>> LabelStudioDataFetcher(\"../proje_im_procjcdlLG/\")\n",
    "    Traceback (most recent call last):\n",
    "        ...\n",
    "    FileNotFoundError: The file does not exist: ../proje_im_procjcdlLG/\n",
    "    \"\"\"\n",
    "    def __init__(self, result_file: str):\n",
    "        self.path = Path(result_file)\n",
    "        if not self.path.exists():\n",
    "            raise FileNotFoundError(f\"The file does not exist: {result_file}\")\n",
    "        self.get_image_data()\n",
    "        self.labels, self.filenames = self.get_labels_and_paths()\n",
    "    \n",
    "    def get_image_data(self) -> None:\n",
    "        with open(self.path, \"r\") as content:\n",
    "            self.tasks = json.load(content)\n",
    "            \n",
    "    def get_labels_and_paths(self) -> Tuple[List[str], List[Path]]:\n",
    "        \"\"\"\n",
    "        Take a list of tasks as argument and return two lists:\n",
    "            - labels: List of labels\n",
    "            - filenames: List of filenames\n",
    "        \"\"\"\n",
    "        list_of_tasks = ExportedResults(tasks=self.tasks)\n",
    "        return zip(*[\n",
    "            (\n",
    "                task.completions[0].result[0].value.choices[0],\n",
    "                Path(task.task_path)\n",
    "            )\n",
    "            for task in list_of_tasks.tasks\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from fastai.vision import ImageDataBunch, get_transforms, models, cnn_learner, accuracy\n",
    "\n",
    "def fastai_image_classifier(image_dir, filenames, labels, output_dir):\n",
    "    \"\"\"\n",
    "    This script provides FastAI-compatible training for the input labeled images\n",
    "    :param image_dir: directory with images\n",
    "    :param filenames: image filenames\n",
    "    :param labels: image labels\n",
    "    :param output_dir: output directory where results will be exported\n",
    "    :return: fastai.basic_train.Learner object\n",
    "    \"\"\"\n",
    "    tfms = get_transforms()\n",
    "    data = ImageDataBunch.from_lists(\n",
    "        Path(image_dir),\n",
    "        filenames,\n",
    "        labels=labels,\n",
    "        ds_tfms=tfms,\n",
    "        size=224,\n",
    "        bs=4\n",
    "    )\n",
    "    learn = cnn_learner(data, models.resnet18, metrics=accuracy, path=output_dir)\n",
    "    learn.fit_one_cycle(2) # Here the par 20 represents the number of epoch\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to train our model using the function fastai_image_classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.477970</td>\n",
       "      <td>2.144558</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.956651</td>\n",
       "      <td>1.420742</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fetcher = LabelStudioDataFetcher(result_file)\n",
    "fetcher.get_image_data()\n",
    "labels, filenames = fetcher.get_labels_and_paths()\n",
    "learn = fastai_image_classifier(image_dir, filenames, labels, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Back', 'Discard', 'Front', 'Left', 'Right']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.data.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Letâ€™s try this model: ðŸ˜Š "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import open_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(open_image(\"../car_dataset/cars_test/00061.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(open_image(\"../car_dataset/cars_test/00029.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(open_image(\"../car_dataset/cars_test/00322.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(open_image(\"../car_dataset/cars_test/00362.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(open_image(\"../car_dataset/cars_test/ji.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got the right answer for the last tests.\n",
    "\n",
    "We just have to call learn.export to save all the information of our Learner object for inference: the stuff we need in the DataBunch (transforms, classes, normalization...), the model with its weights and all the callbacks our Learner was using. Everything will be in a file named export.pkl in the folder learn.path.\n",
    "\n",
    "For more informations, see: https://docs.fast.ai/tutorial.inference.html#A-classification-problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the folder models contains the file export.pkl \n",
    "\n",
    "Letâ€™s use this exported file in order to feed a new model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import load_learner\n",
    "new_model = load_learner('../models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.predict(open_image(\"../car_dataset/cars_test/00266.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Back,\n",
       " tensor(0),\n",
       " tensor([9.9872e-01, 3.6774e-05, 1.3523e-05, 2.9802e-04, 9.3096e-04]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(open_image(\"../car_dataset/cars_test/00216.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Left,\n",
       " tensor(3),\n",
       " tensor([3.8665e-06, 8.7824e-07, 6.3761e-07, 9.9865e-01, 1.3466e-03]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(open_image(\"../car_dataset/cars_test/00167.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Front,\n",
       " tensor(2),\n",
       " tensor([1.5775e-01, 9.6136e-04, 7.9509e-01, 4.5905e-02, 2.9117e-04]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(open_image(\"../car_dataset/cars_test/00213.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category Discard,\n",
       " tensor(1),\n",
       " tensor([9.7729e-05, 9.8653e-01, 5.9017e-04, 2.0625e-03, 1.0719e-02]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.predict(open_image(\"../car_dataset/cars_test/sony.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we got the right answer!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* References:\n",
    "\n",
    "https://docs.fast.ai/basic_train.html#Learner\n",
    "\n",
    "https://forums.fast.ai/t/how-to-make-predictions-with-vision-learner-solved/34456/15\n",
    "\n",
    "https://docs.fast.ai/tutorial.inference.html#A-classification-problem\n",
    "\n",
    "https://github.com/gdoteof/neuralnet_stuff/blob/master/kaggle_whales.ipynb\n",
    "\n",
    "https://docs.fast.ai/vision.image.html#open_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "python3.7 (poc1_vision)",
   "language": "python",
   "name": "poc1_vision"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
